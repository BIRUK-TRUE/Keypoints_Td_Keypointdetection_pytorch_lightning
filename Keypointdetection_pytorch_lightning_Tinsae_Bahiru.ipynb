{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/tlpss/keypoint-detection.git\n%cd keypoint-detection/\n%cd ..","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:30:14.608229Z","iopub.execute_input":"2024-11-12T19:30:14.608544Z","iopub.status.idle":"2024-11-12T19:30:17.033572Z","shell.execute_reply.started":"2024-11-12T19:30:14.608496Z","shell.execute_reply":"2024-11-12T19:30:17.032409Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'keypoint-detection'...\nremote: Enumerating objects: 987, done.\u001b[K\nremote: Counting objects: 100% (584/584), done.\u001b[K\nremote: Compressing objects: 100% (226/226), done.\u001b[K\nremote: Total 987 (delta 420), reused 451 (delta 357), pack-reused 403 (from 1)\u001b[K\nReceiving objects: 100% (987/987), 3.70 MiB | 14.04 MiB/s, done.\nResolving deltas: 100% (565/565), done.\n/kaggle/working/keypoint-detection\n/kaggle/working\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install pytorch\n!pip install torchvision\n!pip install wandb\n!pip install setuptools\n!pip install torch\n!pip install torchvision\n!pip install pytorch-lightning\n!pip install torchmetrics\n!pip install wandb\n!pip install timm\n!pip install tqdm\n!pip install pytest\n!pip install pre-commit\n!pip install scikit-image\n!pip install albumentations\n!pip install matplotlib\n!pip install pydantic\n!pip install fiftyone","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:30:17.036156Z","iopub.execute_input":"2024-11-12T19:30:17.036868Z","iopub.status.idle":"2024-11-12T19:34:26.712682Z","shell.execute_reply.started":"2024-11-12T19:30:17.036819Z","shell.execute_reply":"2024-11-12T19:34:26.711758Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorch\n  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pytorch\n  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-x2ai7tsm/pytorch_aa97bc7f2490401085cde5521a3ea540/setup.py\", line 15, in <module>\n  \u001b[31m   \u001b[0m     raise Exception(message)\n  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\nFailed to build pytorch\n\u001b[31mERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.4.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (70.0.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.4.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.4.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.4.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.7)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.4.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.4.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.7)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (70.0.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.9)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.25.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (8.3.3)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest) (21.3)\nRequirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest) (2.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest) (3.1.2)\nCollecting pre-commit\n  Downloading pre_commit-4.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting cfgv>=2.0.0 (from pre-commit)\n  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\nCollecting identify>=1.0.0 (from pre-commit)\n  Downloading identify-2.6.2-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting nodeenv>=0.11.1 (from pre-commit)\n  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from pre-commit) (6.0.2)\nRequirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.10/site-packages (from pre-commit) (20.21.0)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit) (0.3.8)\nRequirement already satisfied: filelock<4,>=3.4.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit) (3.15.1)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit) (3.11.0)\nDownloading pre_commit-4.0.1-py2.py3-none-any.whl (218 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\nDownloading identify-2.6.2-py2.py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\nInstalling collected packages: nodeenv, identify, cfgv, pre-commit\nSuccessfully installed cfgv-3.4.0 identify-2.6.2 nodeenv-1.9.1 pre-commit-4.0.1\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (0.23.2)\nRequirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.26.4)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.14.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image) (3.1.2)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.17)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\nRequirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.23.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\nRequirement already satisfied: albucore==0.0.17 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.17)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.1.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (2.9.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic) (4.12.2)\nCollecting fiftyone\n  Downloading fiftyone-1.0.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from fiftyone) (22.1.0)\nCollecting argcomplete (from fiftyone)\n  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.12.3)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.26.100)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.2.4)\nCollecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n  Downloading dacite-1.7.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: Deprecated in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.2.14)\nCollecting ftfy (from fiftyone)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: humanize in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.9.0)\nCollecting hypercorn>=0.13.2 (from fiftyone)\n  Downloading hypercorn-0.17.3-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: Jinja2>=3 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.1.4)\nCollecting kaleido!=0.2.1.post1 (from fiftyone)\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.7.5)\nCollecting mongoengine==0.24.2 (from fiftyone)\n  Downloading mongoengine-0.24.2-py3-none-any.whl.metadata (6.7 kB)\nCollecting motor>=2.5 (from fiftyone)\n  Downloading motor-3.6.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fiftyone) (21.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2.2.2)\nRequirement already satisfied: Pillow>=6.2 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (10.3.0)\nRequirement already satisfied: plotly>=4.14 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (5.22.0)\nCollecting pprintpp (from fiftyone)\n  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from fiftyone) (5.9.3)\nRequirement already satisfied: pymongo<4.9,>=3.12 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.13.0)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2024.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from fiftyone) (6.0.2)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2024.5.15)\nRequirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.3.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.23.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.14.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from fiftyone) (70.0.0)\nCollecting sseclient-py<2,>=1.7.2 (from fiftyone)\n  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting sse-starlette<1,>=0.10.3 (from fiftyone)\n  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: starlette>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.37.2)\nCollecting strawberry-graphql (from fiftyone)\n  Downloading strawberry_graphql-0.248.1-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.9.0)\nCollecting xmltodict (from fiftyone)\n  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\nCollecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\nCollecting pydash (from fiftyone)\n  Downloading pydash-8.0.4-py3-none-any.whl.metadata (4.5 kB)\nCollecting fiftyone-brain<0.18,>=0.17.0 (from fiftyone)\n  Downloading fiftyone_brain-0.17.0-py3-none-any.whl.metadata (12 kB)\nCollecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n  Downloading fiftyone_db-1.1.7.tar.gz (7.9 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting voxel51-eta<0.14,>=0.13.0 (from fiftyone)\n  Downloading voxel51_eta-0.13.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.10.0.84)\nRequirement already satisfied: exceptiongroup>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (1.2.0)\nRequirement already satisfied: h11 in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\nCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting priority (from hypercorn>=0.13.2->fiftyone)\n  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl.metadata (327 bytes)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (4.12.2)\nCollecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3->fiftyone) (2.1.5)\nINFO: pip is looking at multiple versions of motor to determine which version is compatible with other requirements. This could take a while.\nCollecting motor>=2.5 (from fiftyone)\n  Downloading motor-3.5.3-py3-none-any.whl.metadata (21 kB)\nCollecting pymongo<4.9,>=3.12 (from fiftyone)\n  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.14->fiftyone) (8.3.0)\nRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from pymongo<4.9,>=3.12->fiftyone) (2.6.1)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette>=0.24.0->fiftyone) (4.4.0)\nRequirement already satisfied: httpx>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.27.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (0.3.8)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.0.0)\nCollecting glob2 (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading glob2-0.7.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting jsonlines (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting py7zr (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.9.0.post0)\nCollecting rarfile (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.16.0)\nRequirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.4.0)\nCollecting tzlocal (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.26.18)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->fiftyone) (2.5)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->fiftyone)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->fiftyone) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->fiftyone) (0.6.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated->fiftyone) (1.16.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->fiftyone) (0.2.13)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (3.1.2)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->fiftyone) (2024.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (2024.5.22)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fiftyone) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fiftyone) (3.5.0)\nCollecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql->fiftyone)\n  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.1)\nCollecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.5)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->voxel51-eta<0.14,>=0.13.0->fiftyone) (23.2.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->voxel51-eta<0.14,>=0.13.0->fiftyone) (3.3.2)\nDownloading fiftyone-1.0.2-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dacite-1.7.0-py3-none-any.whl (12 kB)\nDownloading fiftyone_brain-0.17.0-py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hypercorn-0.17.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading motor-3.5.3-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\nDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\nDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\nDownloading voxel51_eta-0.13.0-py2.py3-none-any.whl (943 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.1/943.1 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\nDownloading pydash-8.0.4-py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading strawberry_graphql-0.248.1-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading priority-2.0.0-py3-none-any.whl (8.9 kB)\nDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\nDownloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\nDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\nDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\nDownloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\nDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fiftyone-db, glob2\n  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.7-py3-none-manylinux1_x86_64.whl size=42156157 sha256=86eb8b3647334b67958d1f729a3ce51b2dae498dbd31cfdeb5c498da6b7f1a30\n  Stored in directory: /root/.cache/pip/wheels/ce/8b/e8/4f778229cacacc9c4e9871a9e0d7bce98fc99b8c01af0ea669\n  Building wheel for glob2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9302 sha256=de2437339bd89eea40ab9e3dd3896f5477aec3c0c8eb3aa220ae0c4b45254a0e\n  Stored in directory: /root/.cache/pip/wheels/37/07/ce/cbe8d31ad93224571b49fa03f8a5da11cdb31d3845ff73e0f3\nSuccessfully built fiftyone-db glob2\nInstalling collected packages: sseclient-py, pprintpp, kaleido, glob2, xmltodict, wsproto, tzlocal, taskgroup, rarfile, pyzstd, pyppmd, pymongo, pydash, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, inflate64, hyperframe, hpack, graphql-core, ftfy, fiftyone-db, dacite, argcomplete, strawberry-graphql, py7zr, motor, mongoengine, h2, botocore, universal-analytics-python3, sse-starlette, hypercorn, fiftyone-brain, voxel51-eta, fiftyone\n  Attempting uninstall: pymongo\n    Found existing installation: pymongo 3.13.0\n    Uninstalling pymongo-3.13.0:\n      Successfully uninstalled pymongo-3.13.0\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.8.1\n    Uninstalling dacite-1.8.1:\n      Successfully uninstalled dacite-1.8.1\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.35.23\n    Uninstalling botocore-1.35.23:\n      Successfully uninstalled botocore-1.35.23\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\napache-beam 2.46.0 requires pymongo<4.0.0,>=3.8.0, but you have pymongo 4.8.0 which is incompatible.\nydata-profiling 4.10.0 requires dacite>=1.8, but you have dacite 1.7.0 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed argcomplete-3.5.1 botocore-1.29.165 dacite-1.7.0 fiftyone-1.0.2 fiftyone-brain-0.17.0 fiftyone-db-1.1.7 ftfy-6.3.1 glob2-0.7 graphql-core-3.2.5 h2-4.1.0 hpack-4.0.0 hypercorn-0.17.3 hyperframe-6.0.1 inflate64-1.0.0 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.5.3 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.21.0 pydash-8.0.4 pymongo-4.8.0 pyppmd-1.1.0 pyzstd-0.16.2 rarfile-4.2 sse-starlette-0.10.3 sseclient-py-1.8.0 strawberry-graphql-0.248.1 taskgroup-0.0.0a4 tzlocal-5.2 universal-analytics-python3-1.1.1 voxel51-eta-0.13.0 wsproto-1.2.0 xmltodict-0.14.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:34:26.714068Z","iopub.execute_input":"2024-11-12T19:34:26.714399Z","iopub.status.idle":"2024-11-12T19:38:49.056217Z","shell.execute_reply.started":"2024-11-12T19:34:26.714364Z","shell.execute_reply":"2024-11-12T19:38:49.055176Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"pip install -e\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:49.058195Z","iopub.execute_input":"2024-11-12T19:38:49.058765Z","iopub.status.idle":"2024-11-12T19:38:50.516034Z","shell.execute_reply.started":"2024-11-12T19:38:49.058726Z","shell.execute_reply":"2024-11-12T19:38:50.514872Z"}},"outputs":[{"name":"stdout","text":"\nUsage:   \n  /opt/conda/bin/python3.10 -m pip install [options] <requirement specifier> [package-index-options] ...\n  /opt/conda/bin/python3.10 -m pip install [options] -r <requirements file> [package-index-options] ...\n  /opt/conda/bin/python3.10 -m pip install [options] [-e] <vcs project url> ...\n  /opt/conda/bin/python3.10 -m pip install [options] [-e] <local project path> ...\n  /opt/conda/bin/python3.10 -m pip install [options] <archive url/path> ...\n\n-e option requires 1 argument\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/keypoint-detection')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:50.517486Z","iopub.execute_input":"2024-11-12T19:38:50.517825Z","iopub.status.idle":"2024-11-12T19:38:50.522261Z","shell.execute_reply.started":"2024-11-12T19:38:50.517789Z","shell.execute_reply":"2024-11-12T19:38:50.521321Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"\n***TYPE***","metadata":{}},{"cell_type":"code","source":"    \"\"\" avoid circular imports by separating types\"\"\"\nfrom typing import List, Tuple\n\nKEYPOINT_TYPE = Tuple[int, int]  # (u,v)\nCOCO_KEYPOINT_TYPE = Tuple[int, int, int]  # (u,v,f)\nCHANNEL_KEYPOINTS_TYPE = List[KEYPOINT_TYPE]\nIMG_KEYPOINTS_TYPE = List[CHANNEL_KEYPOINTS_TYPE]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:50.523539Z","iopub.execute_input":"2024-11-12T19:38:50.523919Z","iopub.status.idle":"2024-11-12T19:38:50.534586Z","shell.execute_reply.started":"2024-11-12T19:38:50.523864Z","shell.execute_reply":"2024-11-12T19:38:50.533851Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"***augmentations***","metadata":{}},{"cell_type":"code","source":"import typing\nfrom typing import List\n\nimport albumentations as A\n\nfrom keypoint_detection.types import IMG_KEYPOINTS_TYPE, KEYPOINT_TYPE\n\n\nclass MultiChannelKeypointsCompose(A.Compose):\n    \"\"\"A subclass of Albumentations.Compose to accomodate for multiple groups/channels of keypoints.\n    Some transforms (crop e.g.) will result in certain keypoints no longer being in the new image. Albumentations can remove them, but since it operates\n    on a single list of keypoints, the transformed keypoints need to be associated to their channel afterwards. Albumentations has support for labels to accomodate this,\n    so we label each keypoint with the index of its channel.\n    \"\"\"\n\n    def __init__(self, transforms, p: float = 1):\n        keypoint_params = A.KeypointParams(format=\"xy\", label_fields=[\"channel_labels\"], remove_invisible=True)\n        super().__init__(transforms, keypoint_params=keypoint_params, p=p)\n\n    def __call__(self, *args, force_apply: bool = False, **data) -> typing.Dict[str, typing.Any]:\n\n        # flatten and create channel labels (=str(index))\n        keypoints = data[\"keypoints\"]\n        self.create_channel_labels(keypoints)\n        flattened_keypoints = self.flatten_keypoints(keypoints)\n        data[\"keypoints\"] = flattened_keypoints\n        data[\"channel_labels\"] = self.flatten_keypoints(self.create_channel_labels(keypoints))\n        # apply transforms\n        result_dict = super().__call__(*args, force_apply=force_apply, **data)\n\n        # rearrange keypoints by channel\n        transformed_flattened_keypoints = result_dict[\"keypoints\"]\n        transformed_flattened_labels = result_dict[\"channel_labels\"]\n        transformed_keypoints = self.order_transformed_keypoints_by_channel(\n            keypoints, transformed_flattened_keypoints, transformed_flattened_labels\n        )\n        result_dict[\"keypoints\"] = transformed_keypoints\n        return result_dict\n\n    @staticmethod\n    def flatten_keypoints(keypoints: IMG_KEYPOINTS_TYPE) -> List[KEYPOINT_TYPE]:\n        return [item for sublist in keypoints for item in sublist]\n\n    @staticmethod\n    def create_channel_labels(keypoints: IMG_KEYPOINTS_TYPE):\n        channel_labels = [[str(i)] * len(keypoints[i]) for i in range(len(keypoints))]\n        return channel_labels\n\n    @staticmethod\n    def order_transformed_keypoints_by_channel(\n        original_keypoints: IMG_KEYPOINTS_TYPE,\n        transformed_keypoints: List[KEYPOINT_TYPE],\n        transformed_channel_labels: List[str],\n    ) -> IMG_KEYPOINTS_TYPE:\n        ordered_transformed_keypoints = [[] for _ in original_keypoints]\n        for transformed_keypoint, channel_label in zip(transformed_keypoints, transformed_channel_labels):\n            channel_idx = int(channel_label)\n            ordered_transformed_keypoints[channel_idx].append(transformed_keypoint)\n\n        return ordered_transformed_keypoints","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:50.536128Z","iopub.execute_input":"2024-11-12T19:38:50.536416Z","iopub.status.idle":"2024-11-12T19:38:51.906447Z","shell.execute_reply.started":"2024-11-12T19:38:50.536385Z","shell.execute_reply":"2024-11-12T19:38:51.905486Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"***coco_parser***","metadata":{}},{"cell_type":"code","source":"from typing import List, Optional, Union\n\nfrom pydantic import BaseModel\n\n\"\"\"Custom parser for COCO keypoints JSON\"\"\"\n\nLicenseID = int\nImageID = int\nCategoryID = int\nAnnotationID = int\nSegmentation = List[List[Union[float, int]]]\nFileName = str\nRelativepath = str\nUrl = str\n\n\nclass CocoInfo(BaseModel):\n    description: str\n    url: Url\n    version: str\n    year: int\n    contributor: str\n    date_created: str\n\n\nclass CocoLicenses(BaseModel):\n    url: Url\n    id: LicenseID\n    name: str\n\n\nclass CocoImage(BaseModel):\n    license: Optional[LicenseID] = None\n    file_name: Relativepath\n    height: int\n    width: int\n    id: ImageID\n\n\nclass CocoKeypointCategory(BaseModel):\n    supercategory: str  # should be set to \"name\" for root category\n    id: CategoryID\n    name: str\n    keypoints: List[str]\n    skeleton: Optional[List[List[int]]] = None\n\n\nclass CocoKeypointAnnotation(BaseModel):\n    category_id: CategoryID\n    id: AnnotationID\n    image_id: ImageID\n\n    num_keypoints: Optional[int] = None\n    # COCO keypoints can be floats if they specify the exact location of the keypoint (e.g. from CVAT)\n    # even though COCO format specifies zero-indexed integers (i.e. every keypoint in the [0,1]x [0.1] pixel box becomes (0,0)\n    keypoints: List[float]\n\n    # TODO: add checks.\n    # @validator(\"keypoints\")\n    # def check_amount_of_keypoints(cls, v, values, **kwargs):\n    #     assert len(v) // 3 == values[\"num_keypoints\"]\n\n\nclass CocoKeypoints(BaseModel):\n    \"\"\"Parser Class for COCO keypoints JSON\n\n    Example:\n    with open(\"path\",\"r\") as file:\n        data = json.load(file) # dict\n        parsed_data = COCOKeypoints(**data)\n    \"\"\"\n\n    info: Optional[CocoInfo] = None\n    licenses: Optional[List[CocoLicenses]] = None\n    images: List[CocoImage]\n    categories: List[CocoKeypointCategory]\n    annotations: List[CocoKeypointAnnotation]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:51.907771Z","iopub.execute_input":"2024-11-12T19:38:51.908361Z","iopub.status.idle":"2024-11-12T19:38:51.929718Z","shell.execute_reply.started":"2024-11-12T19:38:51.908315Z","shell.execute_reply":"2024-11-12T19:38:51.928736Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"***imageloader***","metadata":{}},{"cell_type":"code","source":"import abc\nimport random\nimport time\n\nimport numpy as np\nfrom skimage import io\nfrom torch.utils.data import Dataset\n\n\nclass ImageLoader:\n    def get_image(self, path: str, idx: int) -> np.ndarray:\n        \"\"\"\n        read the image from disk and return as np array\n        \"\"\"\n        # load images @runtime from disk\n        image = io.imread(path)\n        return image\n\n\nclass BaseImageLoaderDecorator(ImageLoader):\n    def __init__(self, image_loader: ImageLoader) -> None:\n        self.image_loader = image_loader\n\n    @abc.abstractmethod\n    def get_image(self, path: str, idx: int) -> np.ndarray:\n        pass\n\n\nclass IOSafeImageLoaderDecorator(BaseImageLoaderDecorator):\n    \"\"\"\n    IO safe loader that re-attempts to load image from disk (important for GPULab infrastructure @ UGent)\n    \"\"\"\n\n    def __init__(self, image_loader: ImageLoader) -> None:\n        super().__init__(image_loader)\n        self.n_io_attempts = 4\n\n    def get_image(self, path: str, idx: int) -> np.ndarray:\n        sleep_time_in_seconds = 1\n        for j in range(self.n_io_attempts):\n            try:\n                image = self.image_loader.get_image(path, idx)\n                return image\n            except IOError:\n                if j == self.n_io_attempts - 1:\n                    raise IOError(f\"Could not load image for dataset entry with path {path}, index {idx}\")\n\n                sleep_time = max(random.gauss(sleep_time_in_seconds, j), 0)\n                print(f\"caught IOError in {j}th attempt to load image for {path}, sleeping for {sleep_time} seconds\")\n                time.sleep(sleep_time)\n                sleep_time_in_seconds *= 2\n\n\nclass CachedImageLoaderDecorator(BaseImageLoaderDecorator):\n    \"\"\"\n    Image dataloader that caches the images after the first fetch in np.uint8 format.\n    Requires enough CPU Memory to fit entire dataset (img_size^2*3*N_images B)\n\n    This is done lazy instead of prefetching, as the torch dataloader is highly optimized to prefetch data during forward passes etc.\n     Impact is expected to be not too big.. TODO -> benchmark.\n\n    Furthermore, this caching requires to set num_workers to 0, as the dataset object is copied by each dataloader worker.\n    \"\"\"\n\n    def __init__(self, image_loader: ImageLoader) -> None:\n        super().__init__(image_loader)\n\n        self.cache = []\n        self.cache_index_mapping = {}\n\n    def get_image(self, path: str, idx: int) -> np.ndarray:\n        if path not in self.cache_index_mapping:\n            img = super().get_image(path, idx)\n            self.cache.append(img)\n            self.cache_index_mapping.update({path: len(self.cache) - 1})\n            return img\n\n        else:\n            return self.cache[self.cache_index_mapping[path]]\n\n\nclass ImageDataset(Dataset, abc.ABC):\n    def __init__(self, imageloader: ImageLoader = None):\n        if imageloader is None:\n            self.image_loader = IOSafeImageLoaderDecorator(ImageLoader())\n\n        else:\n            assert isinstance(imageloader, ImageLoader)\n            self.image_loader = imageloader\n\n    def __getitem__(self, index):\n        pass\n\n    def __len__(self):\n        pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:51.931582Z","iopub.execute_input":"2024-11-12T19:38:51.932004Z","iopub.status.idle":"2024-11-12T19:38:55.456659Z","shell.execute_reply.started":"2024-11-12T19:38:51.931961Z","shell.execute_reply":"2024-11-12T19:38:55.455857Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"***unlabeled_dataset***","metadata":{}},{"cell_type":"code","source":"import os\n\nimport torch\nfrom torchvision.transforms import ToTensor\n\nfrom keypoint_detection.data.imageloader import ImageDataset\n\n\nclass UnlabeledKeypointsDataset(ImageDataset):\n    \"\"\"\n    Simple dataset to run inference on unlabeled data\n    \"\"\"\n\n    def __init__(\n        self,\n        image_dataset_path: str,\n        **kwargs,\n    ):\n        super().__init__()\n        self.image_paths = os.listdir(image_dataset_path)\n        self.image_paths = [image_dataset_path + f\"/{path}\" for path in self.image_paths]\n\n        self.transform = ToTensor()  # convert images to Torch Tensors\n\n    def __getitem__(self, index):\n        if torch.is_tensor(index):\n            index = index.tolist()\n        index = int(index)\n\n        image_path = self.image_paths[index]\n        image = self.image_loader.get_image(image_path, index)\n        image = self.transform(image)\n\n        return image\n\n    def __len__(self):\n        return len(self.image_paths)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:55.461281Z","iopub.execute_input":"2024-11-12T19:38:55.461810Z","iopub.status.idle":"2024-11-12T19:38:56.626934Z","shell.execute_reply.started":"2024-11-12T19:38:55.461776Z","shell.execute_reply":"2024-11-12T19:38:56.626125Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"***datamodule***","metadata":{}},{"cell_type":"code","source":"import argparse\nimport random\n\nimport albumentations as A\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\nfrom torch.utils.data import DataLoader, Subset\n\nfrom keypoint_detection.data.augmentations import MultiChannelKeypointsCompose\nfrom keypoint_detection.data.coco_dataset import COCOKeypointsDataset\n\n\nclass KeypointsDataModule(pl.LightningDataModule):\n    @staticmethod\n    def add_argparse_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n        \"\"\"\n        add named arguments from the init function to the parser\n        \"\"\"\n        parser = parent_parser.add_argument_group(\"KeypointsDatamodule\")\n        parser.add_argument(\"--batch_size\", default=16, type=int)\n        parser.add_argument(\"--validation_split_ratio\", default=0.25, type=float)\n        parser.add_argument(\"--num_workers\", default=4, type=int)\n        parser.add_argument(\n            \"--json_dataset_path\",\n            type=str,\n            help=\"Absolute path to the json file that defines the train dataset according to the COCO format.\",\n            required=True,\n        )\n        parser.add_argument(\n            \"--json_validation_dataset_path\",\n            type=str,\n            help=\"Absolute path to the json file that defines the validation dataset according to the COCO format. \\\n                If not specified, the train dataset will be split to create a validation set if there is one.\",\n        )\n        parser.add_argument(\n            \"--json_test_dataset_path\",\n            type=str,\n            help=\"Absolute path to the json file that defines the test dataset according to the COCO format. \\\n                If not specified, no test set evaluation will be performed at the end of training.\",\n        )\n\n        parser.add_argument(\"--augment_train\", dest=\"augment_train\", default=False, action=\"store_true\")\n        parent_parser = COCOKeypointsDataset.add_argparse_args(parent_parser)\n\n        return parent_parser\n\n    def __init__(\n        self,\n        keypoint_channel_configuration: list[list[str]],\n        batch_size: int = 16,\n        validation_split_ratio: float = 0.25,\n        num_workers: int = 2,\n        json_dataset_path: str = None,\n        json_validation_dataset_path: str = None,\n        json_test_dataset_path=None,\n        augment_train: bool = False,\n        **kwargs,\n    ):\n        super().__init__()\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.augment_train = augment_train\n\n        self.train_dataset = None\n        if json_dataset_path:\n            self.train_dataset = COCOKeypointsDataset(json_dataset_path, keypoint_channel_configuration, **kwargs)\n\n        self.validation_dataset = None\n        self.test_dataset = None\n\n        if json_validation_dataset_path:\n            self.validation_dataset = COCOKeypointsDataset(\n                json_validation_dataset_path, keypoint_channel_configuration, **kwargs\n            )\n        else:\n            if self.train_dataset is not None:\n                print(f\"splitting the train set to create a validation set with ratio {validation_split_ratio} \")\n                self.train_dataset, self.validation_dataset = KeypointsDataModule._split_dataset(\n                    self.train_dataset, validation_split_ratio\n                )\n\n        if json_test_dataset_path:\n            self.test_dataset = COCOKeypointsDataset(json_test_dataset_path, keypoint_channel_configuration, **kwargs)\n\n        # create the transforms if needed and set them to the datasets\n        if augment_train:\n            print(\"Augmenting the training dataset!\")\n            img_height, img_width = self.train_dataset[0][0].shape[1], self.train_dataset[0][0].shape[2]\n            aspect_ratio = img_width / img_height\n            train_transform = MultiChannelKeypointsCompose(\n                [\n                    A.ColorJitter(p=0.8),\n                    A.RandomBrightnessContrast(p=0.8),\n                    A.RandomResizedCrop(\n                        img_height, img_width, scale=(0.8, 1.0), ratio=(0.9 * aspect_ratio, 1.1 * aspect_ratio), p=1.0\n                    ),\n                    A.GaussianBlur(p=0.2, blur_limit=(3, 3)),\n                    A.Sharpen(p=0.2),\n                    A.GaussNoise(),\n                ]\n            )\n            if isinstance(self.train_dataset, COCOKeypointsDataset):\n                self.train_dataset.transform = train_transform\n            elif isinstance(self.train_dataset, Subset):\n                # if the train dataset is a subset, we need to set the transform to the underlying dataset\n                # otherwise the transform will not be applied..\n                assert isinstance(self.train_dataset.dataset, COCOKeypointsDataset)\n                self.train_dataset.dataset.transform = train_transform\n\n    @staticmethod\n    def _split_dataset(dataset, validation_split_ratio):\n        validation_size = int(validation_split_ratio * len(dataset))\n        train_size = len(dataset) - validation_size\n        train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])\n        print(f\"train size: {len(train_dataset)}\")\n        print(f\"validation size: {len(validation_dataset)}\")\n        return train_dataset, validation_dataset\n\n    def train_dataloader(self):\n        # usually need to seed workers for reproducibility\n        # cf. https://pytorch.org/docs/stable/notes/randomness.html\n        # but PL does for us in their seeding function:\n        # https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n\n        if self.train_dataset is None:\n            return None\n\n        dataloader = DataLoader(\n            self.train_dataset,\n            self.batch_size,\n            shuffle=True,\n            num_workers=self.num_workers,\n            collate_fn=COCOKeypointsDataset.collate_fn,\n            pin_memory=True,  # usually a little faster\n        )\n        return dataloader\n\n    def val_dataloader(self):\n        # usually need to seed workers for reproducibility\n        # cf. https://pytorch.org/docs/stable/notes/randomness.html\n        # but PL does for us in their seeding function:\n        # https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n\n        if self.validation_dataset is None:\n            return None\n\n        dataloader = DataLoader(\n            self.validation_dataset,\n            self.batch_size,\n            shuffle=False,\n            num_workers=self.num_workers,\n            collate_fn=COCOKeypointsDataset.collate_fn,\n        )\n        return dataloader\n\n    def test_dataloader(self):\n\n        if self.test_dataset is None:\n            return None\n        dataloader = DataLoader(\n            self.test_dataset,\n            min(4, self.batch_size),  # 4 as max for better visualization in wandb.\n            shuffle=False,\n            num_workers=0,\n            collate_fn=COCOKeypointsDataset.collate_fn,\n        )\n        return dataloader\n\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:56.628162Z","iopub.execute_input":"2024-11-12T19:38:56.628635Z","iopub.status.idle":"2024-11-12T19:38:58.796869Z","shell.execute_reply.started":"2024-11-12T19:38:56.628587Z","shell.execute_reply":"2024-11-12T19:38:58.795570Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"***coco_dataset***","metadata":{}},{"cell_type":"code","source":"import argparse\nimport json\nimport math\nimport typing\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nimport albumentations as A\nimport torch\nfrom torchvision.transforms import ToTensor\n\nfrom keypoint_detection.data.coco_parser import CocoImage, CocoKeypointCategory, CocoKeypoints\nfrom keypoint_detection.data.imageloader import ImageDataset, ImageLoader\nfrom keypoint_detection.types import COCO_KEYPOINT_TYPE, IMG_KEYPOINTS_TYPE\n\n\nclass COCOKeypointsDataset(ImageDataset):\n    \"\"\"Pytorch Dataset for COCO-formatted Keypoint dataset\n\n    cf. https://cocodataset.org/#format-data for more information. We expect each annotation to have at least the keypoints and num_keypoints fields.\n    Each category should also have keypoints. For more information on the required fields and data types, have a look at the COCO parser in `coco_parser.py`.\n\n    The dataset builds an index during the init call that maps from each image_id to a list of all keypoints of all semantic types in the dataset.\n\n    The Dataset also expects a keypoint_channel_configuration that maps from the semantic types (the keypoints in all categories of the COCO file) to the channels\n    of the keypoint detector. In the simplest case this is simply a list of all types, but for e.g. symmetric objects or equivalence mapping one could combine different\n    types into one channel. For example if you have category box with keypoints [corner0, corner1, corner2, corner3] you could combine  them in a single channel for the\n    detector by passing as configuration [[corner0,corner1,corner2,corner3]].\n\n    You can also select if you want to train on annotations with flag=1 (occluded).\n\n    The paths in the JSON should be relative to the directory in which the JSON is located.\n\n\n    The __getitem__ function returns [img_path, [keypoints for each channel according to the configuration]]\n    \"\"\"\n\n    @staticmethod\n    def add_argparse_args(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n        \"\"\"\n        add named arguments from the init function to the parser\n        \"\"\"\n        parser = parent_parser.add_argument_group(\"COCOkeypointsDataset\")\n        parser.add_argument(\n            \"--detect_only_visible_keypoints\",\n            dest=\"detect_only_visible_keypoints\",\n            default=False,\n            action=\"store_true\",\n            help=\"If set, only keypoints with flag > 1.0 will be used.\",\n        )\n\n        return parent_parser\n\n    def __init__(\n        self,\n        json_dataset_path: str,\n        keypoint_channel_configuration: list[list[str]],\n        detect_only_visible_keypoints: bool = True,\n        transform: A.Compose = None,\n        imageloader: ImageLoader = None,\n        **kwargs,\n    ):\n        super().__init__(imageloader)\n\n        self.image_to_tensor_transform = ToTensor()\n        self.dataset_json_path = Path(json_dataset_path)\n        self.dataset_dir_path = self.dataset_json_path.parent  # assume paths in JSON are relative to this directory!\n\n        self.keypoint_channel_configuration = keypoint_channel_configuration\n        self.detect_only_visible_keypoints = detect_only_visible_keypoints\n\n        print(f\"{detect_only_visible_keypoints=}\")\n\n        self.random_crop_transform = None\n        self.transform = transform\n        self.dataset = self.prepare_dataset()  # idx: (image, list(keypoints/channel))\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, index) -> Tuple[torch.Tensor, IMG_KEYPOINTS_TYPE]:\n        \"\"\"\n        Returns:\n            (image, keypoints); image = 3xHxW tensor; keypoints = List(c x list( list of K_i keypoints ))\n\n            e.g. for 2 heatmap channels with respectively 1,2 keypoints, the keypoints list will be formatted as\n            [[[u11,v11]],[[u21,v21],[u22,v22]]]\n        \"\"\"\n        if torch.is_tensor(index):\n            index = index.tolist()\n        index = int(index)\n\n        image_path = self.dataset_dir_path / self.dataset[index][0]\n        image = self.image_loader.get_image(str(image_path), index)\n        # remove a-channel if needed\n        if image.shape[2] == 4:\n            image = image[..., :3]\n\n        keypoints = self.dataset[index][1]\n\n        if self.transform:\n            transformed = self.transform(image=image, keypoints=keypoints)\n            image, keypoints = transformed[\"image\"], transformed[\"keypoints\"]\n\n        # convert all keypoints to integers values.\n        # COCO keypoints can be floats if they specify the exact location of the keypoint (e.g. from CVAT)\n        # even though COCO format specifies zero-indexed integers (i.e. every keypoint in the [0,1]x [0.1] pixel box becomes (0,0)\n        # we convert them to ints here, as the heatmap generation will add a 0.5 offset to the keypoint location to center it in the pixel\n        # the distance metrics also operate on integer values.\n\n        # so basically from here on every keypoint is an int that represents the pixel-box in which the keypoint is located.\n        keypoints = [\n            [[math.floor(keypoint[0]), math.floor(keypoint[1])] for keypoint in channel_keypoints]\n            for channel_keypoints in keypoints\n        ]\n        image = self.image_to_tensor_transform(image)\n        return image, keypoints\n\n    def prepare_dataset(self):\n        \"\"\"Prepares the dataset to map from COCO to (img, [keypoints for each channel])\n\n        Returns:\n            [img_path, [list of keypoints for each channel]]\n        \"\"\"\n        with open(self.dataset_json_path, \"r\") as file:\n            data = json.load(file)\n            parsed_coco = CocoKeypoints(**data)\n\n            img_dict: typing.Dict[int, CocoImage] = {}\n            for img in parsed_coco.images:\n                img_dict[img.id] = img\n\n            category_dict: typing.Dict[int, CocoKeypointCategory] = {}\n            for category in parsed_coco.categories:\n                category_dict[category.id] = category\n\n            # iterate over all annotations and create a dict {img_id: {semantic_type : [keypoints]}}\n            # make sure to deal with multiple occurances of same semantic_type in one image (e.g. multipe humans in one image)\n            annotation_dict = defaultdict(\n                lambda: defaultdict(lambda: [])\n            )  # {img_id: {channel : [keypoints for that channel]}}\n            for annotation in parsed_coco.annotations:\n                # add all keypoints from this annotation to the corresponding image in the dict\n\n                img = img_dict[annotation.image_id]\n                category = category_dict[annotation.category_id]\n                semantic_classes = category.keypoints\n\n                keypoints = annotation.keypoints\n                keypoints = self.split_list_in_keypoints(keypoints)\n                for semantic_type, keypoint in zip(semantic_classes, keypoints):\n                    annotation_dict[annotation.image_id][semantic_type].append(keypoint)\n\n            # iterate over each image and all it's annotations\n            # filter the visible keypoints\n            # and group them by channel\n            dataset = []\n            for img_id, keypoint_dict in annotation_dict.items():\n                img_channels_keypoints = [[] for _ in range(len(self.keypoint_channel_configuration))]\n                for semantic_type, keypoints in keypoint_dict.items():\n                    for keypoint in keypoints:\n\n                        if min(keypoint[:2]) < 0 or keypoint[0] > img_dict[img_id].width or keypoint[1] > img_dict[img_id].height:\n                            print(\"keypoint outside of image, ignoring.\")\n                            continue\n                        if self.is_keypoint_visible(keypoint):\n                            channel_idx = self.get_keypoint_channel_index(semantic_type)\n                            if channel_idx > -1:\n                                img_channels_keypoints[channel_idx].append(keypoint[:2])\n\n                dataset.append([img_dict[img_id].file_name, img_channels_keypoints])\n\n            return dataset\n\n    def get_keypoint_channel_index(self, semantic_type: str) -> int:\n        \"\"\"\n        given a semantic type, get it's channel according to the channel configuration.\n        Returns -1 if the semantic type couldn't be found.\n        \"\"\"\n\n        for i, types_in_channel in enumerate(self.keypoint_channel_configuration):\n            if semantic_type in types_in_channel:\n                return i\n        return -1\n\n    def is_keypoint_visible(self, keypoint: COCO_KEYPOINT_TYPE) -> bool:\n        \"\"\"\n        Args:\n            keypoint (list): [u,v,flag]\n\n        Returns:\n            bool: True if current keypoint is considered visible according to the dataset configuration, else False\n        \"\"\"\n        if self.detect_only_visible_keypoints:\n            # filter out occluded keypoints with flag 1.0\n            return keypoint[2] > 1.5\n        else:\n            # filter out non-labeled keypoints with flag 0.0\n            return keypoint[2] > 0.5\n\n    @staticmethod\n    def split_list_in_keypoints(list_to_split: List[COCO_KEYPOINT_TYPE]) -> List[List[COCO_KEYPOINT_TYPE]]:\n        \"\"\"\n        splits list [u1,v1,f1,u2,v2,f2,...] to [[u,v,f],..]\n        \"\"\"\n        n = 3\n        output = [list_to_split[i : i + n] for i in range(0, len(list_to_split), n)]\n        return output\n\n    @staticmethod\n    def collate_fn(data):\n        \"\"\"custom collate function for use with the torch dataloader\n\n        Note that it could have been more efficient to padd for each channel separately, but it's not worth the trouble as even\n        for 100 channels with each 100 occurances the padded data size is still < 1kB..\n\n        Args:\n            data: list of tuples (image, keypoints); image = 3xHxW tensor; keypoints = List(c x list(? keypoints ))\n\n        Returns:\n            (images, keypoints); Images as a torch tensor Nx3xHxW,\n            keypoints is a nested list of lists. where each item is a tensor (K,2) with K the number of keypoints\n            for that channel and that sample:\n\n                List(List(Tensor(K,2))) -> C x N x Tensor(max_keypoints_for_any_channel_in_batch x 2)\n\n        Note there is no padding, as all values need to be unpacked again in the detector to create all the heatmaps,\n        unlike e.g. NLP where you directly feed the padded sequences to the network.\n        \"\"\"\n        images, keypoints = zip(*data)\n\n        # convert the list of keypoints to a 2D tensor\n        keypoints = [[torch.tensor(x) for x in y] for y in keypoints]\n        # reorder to have the different keypoint channels as  first dimension\n        # C x N x K x 2 , K = variable number of keypoints for each (N,C)\n        reordered_keypoints = [[keypoints[i][j] for i in range(len(keypoints))] for j in range(len(keypoints[0]))]\n\n        images = torch.stack(images)\n\n        return images, reordered_keypoints\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:58.798704Z","iopub.execute_input":"2024-11-12T19:38:58.799298Z","iopub.status.idle":"2024-11-12T19:38:58.832541Z","shell.execute_reply.started":"2024-11-12T19:38:58.799254Z","shell.execute_reply":"2024-11-12T19:38:58.831655Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"***base_backbone***","metadata":{}},{"cell_type":"code","source":"import abc\nimport argparse\n\nfrom torch import nn as nn\n\n\nclass Backbone(nn.Module, abc.ABC):\n    \"\"\"Base class for backbones\"\"\"\n\n    def __init__(self):\n        super(Backbone, self).__init__()\n\n    @abc.abstractmethod\n    def get_n_channels_out(self) -> int:\n        raise NotImplementedError\n\n    @staticmethod\n    def add_to_argparse(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n        return parent_parser\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:58.833713Z","iopub.execute_input":"2024-11-12T19:38:58.834005Z","iopub.status.idle":"2024-11-12T19:38:58.847862Z","shell.execute_reply.started":"2024-11-12T19:38:58.833973Z","shell.execute_reply":"2024-11-12T19:38:58.846911Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"***convenext_unet***","metadata":{}},{"cell_type":"code","source":"\"\"\"A Unet-like backbone that uses a (relatively) small imagenet-pretrained ConvNeXt model from timm as encoder.\n\"\"\"\nimport timm\nimport torch\nimport torch.nn as nn\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\n\n\nclass UpSamplingBlock(nn.Module):\n    \"\"\"\n    A very basic Upsampling block (these params have to be learnt from scratch so keep them small)\n\n    First it reduces the number of channels of the incoming layer to the amount of the skip connection with a 1x1 conv\n    then it concatenates them and combines them in a new conv layer.\n\n\n\n    x --> up ---> conv1 --> concat --> conv2 --> norm -> relu\n                  ^\n                  |\n                  skip_x\n    \"\"\"\n\n    def __init__(self, n_channels_in, n_skip_channels_in, n_channels_out, kernel_size):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(\n            in_channels=n_skip_channels_in + n_channels_in,\n            out_channels=n_channels_out,\n            kernel_size=kernel_size,\n            bias=False,\n            padding=\"same\",\n        )\n\n        self.norm1 = nn.BatchNorm2d(n_channels_out)\n        self.relu1 = nn.ReLU()\n\n    def forward(self, x, x_skip):\n        # bilinear is not deterministic, use nearest neighbor instead\n        x = nn.functional.interpolate(x, scale_factor=2.0)\n        x = torch.cat([x, x_skip], dim=1)\n        x = self.conv1(x)\n        x = self.norm1(x)\n        x = self.relu1(x)\n\n        # second conv as in original UNet upsampling block decreases performance\n        # probably because I was using a small dataset that did not have enough data to learn the extra parameters\n        return x\n\n\nclass ConvNeXtUnet(Backbone):\n    \"\"\"\n    Pretrained ConvNeXt as Encoder for the U-Net.\n\n    the outputs of the 3 intermediate CovNext stages are used for skip connections.\n    The output of res4 is considered as the bottleneck and has a 32x resolution reduction!\n\n    femto -> 3M params\n    nano -> 17M params (but only twice as slow)\n\n\n    input                                                   final_conv --- head\n        stem                                            upsampling\n                                                    upsamping\n            res1         --->   1/4             decode3\n                res2     --->   1/8         decode2\n                    res3 --->   1/16    decode1\n                        res4 ---1/32----|\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__()\n        # todo: make desired convnext encoder configurable\n        self.encoder = timm.create_model(\"convnext_femto\", features_only=True, pretrained=True)\n\n        self.decoder_blocks = nn.ModuleList()\n        for i in range(1, 4):\n            channels_in, skip_channels_in = (\n                self.encoder.feature_info.info[-i][\"num_chs\"],\n                self.encoder.feature_info.info[-i - 1][\"num_chs\"],\n            )\n            block = UpSamplingBlock(channels_in, skip_channels_in, skip_channels_in, 3)\n            self.decoder_blocks.append(block)\n\n        self.final_conv = nn.Conv2d(skip_channels_in + 3, skip_channels_in, 3, padding=\"same\")\n\n    def forward(self, x):\n        x_orig = torch.clone(x)\n        features = self.encoder(x)\n\n        x = features.pop()\n        for block in self.decoder_blocks:\n            x = block(x, features.pop())\n        x = nn.functional.interpolate(x, scale_factor=4.0)\n        x = torch.cat([x, x_orig], dim=1)\n        x = self.final_conv(x)\n        return x\n\n    def get_n_channels_out(self):\n        return self.encoder.feature_info.info[0][\"num_chs\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:58.849033Z","iopub.execute_input":"2024-11-12T19:38:58.849365Z","iopub.status.idle":"2024-11-12T19:38:59.188225Z","shell.execute_reply.started":"2024-11-12T19:38:58.849310Z","shell.execute_reply":"2024-11-12T19:38:59.187364Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"***dilated_CNN***","metadata":{}},{"cell_type":"code","source":"\"\"\"A very simple Backbone that uses dilated CNNs without spatial resolution changes.\n\"\"\"\nimport torch\nimport torch.nn as nn\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\n\n\nclass DilatedCnn(Backbone):\n    def __init__(self, n_channels=32, **kwargs):\n        super().__init__()\n        self.n_channels_in = 3\n        self.n_channels = n_channels\n        kernel_size = (3, 3)\n        self.model = nn.Sequential(\n            nn.Conv2d(\n                in_channels=self.n_channels_in,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=2,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=4,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=8,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=16,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=2,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=4,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=8,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                dilation=16,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n            nn.Conv2d(\n                in_channels=n_channels,\n                out_channels=n_channels,\n                kernel_size=kernel_size,\n                padding=\"same\",\n            ),\n            nn.LeakyReLU(),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.model(x)\n\n    def get_n_channels_out(self):\n        return self.n_channels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:59.189542Z","iopub.execute_input":"2024-11-12T19:38:59.189867Z","iopub.status.idle":"2024-11-12T19:38:59.204541Z","shell.execute_reply.started":"2024-11-12T19:38:59.189834Z","shell.execute_reply":"2024-11-12T19:38:59.203631Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"***S3K***","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\n\n\nclass ResNetBlock(nn.Module):\n    \"\"\"\n    based on the basic ResNet Block used in torchvision\n    inspired on https://jarvislabs.ai/blogs/resnet\n    \"\"\"\n\n    def __init__(self, n_channels_in, n_channels=32):\n        super().__init__()\n        self.conv1 = nn.Conv2d(n_channels_in, n_channels, kernel_size=(3, 3), padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(n_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(n_channels, n_channels, kernel_size=(3, 3), padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(n_channels)\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass S3K(Backbone):\n    \"\"\"\n    Backbone (approx) as in the S3K paper by Mel\n    inspired by Peter's version of the backbone.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        self.kernel_size = (3, 3)\n        super(S3K, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=self.kernel_size, padding=\"same\")\n        self.norm1 = nn.BatchNorm2d(num_features=3)\n        self.conv2 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=self.kernel_size, stride=(2, 2))\n        self.norm2 = nn.BatchNorm2d(num_features=16)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=self.kernel_size, stride=(2, 2))\n        self.norm3 = nn.BatchNorm2d(num_features=32)\n        self.res1 = ResNetBlock(32)\n        self.res2 = ResNetBlock(32)\n        self.res3 = ResNetBlock(32)\n\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=self.kernel_size, padding=\"same\")\n        self.up1 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=self.kernel_size, stride=(2, 2))\n\n        self.conv5 = nn.Conv2d(\n            in_channels=32 + 16, out_channels=32, kernel_size=self.kernel_size, padding=\"same\", bias=False\n        )\n        self.norm4 = nn.BatchNorm2d(32)\n        self.up2 = nn.ConvTranspose2d(\n            in_channels=32, out_channels=32, kernel_size=self.kernel_size, stride=(2, 2), output_padding=1\n        )\n        self.conv6 = nn.Conv2d(\n            in_channels=32 + 3, out_channels=32, kernel_size=self.kernel_size, padding=\"same\", bias=False\n        )\n        self.norm5 = nn.BatchNorm2d(32)\n        self.relu = nn.ReLU()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.conv1(x)\n        x_0 = x\n        x = self.norm1(x)\n        x = self.relu(x)\n\n        x = self.conv2(x)\n        x_1 = x\n        x = self.norm2(x)\n        x = self.relu(x)\n\n        x = self.conv3(x)\n        x = self.norm3(x)\n        x = self.relu(x)\n\n        x = self.res1(x)\n\n        x = self.res2(x)\n\n        x = self.res3(x)\n\n        x = self.conv4(x)\n\n        x = self.up1(x)\n        x = torch.cat([x, x_1], dim=1)\n        x = self.conv5(x)\n        x = self.norm4(x)\n        x = self.relu(x)\n\n        x = self.up2(x)\n        x = torch.cat([x, x_0], dim=1)\n        x = self.conv6(x)\n        x = self.norm5(x)\n        x = self.relu(x)\n        return x\n\n    def get_n_channels_out(self):\n        return 32\n\n\nif __name__ == \"__main__\":\n    print(Backbone)\n   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:59.205890Z","iopub.execute_input":"2024-11-12T19:38:59.206285Z","iopub.status.idle":"2024-11-12T19:38:59.230521Z","shell.execute_reply.started":"2024-11-12T19:38:59.206252Z","shell.execute_reply":"2024-11-12T19:38:59.229667Z"}},"outputs":[{"name":"stdout","text":"<class 'keypoint_detection.models.backbones.base_backbone.Backbone'>\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"***unet***","metadata":{}},{"cell_type":"code","source":"\nimport argparse\nimport math\n\nimport torch\nimport torch.nn as nn\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\nfrom keypoint_detection.models.backbones.s3k import ResNetBlock\n\n\nclass MaxPoolDownSamplingBlock(nn.Module):\n    def __init__(self, n_channels_in, n_channels_out, kernel_size):\n        super().__init__()\n        padding = math.floor(kernel_size / 2)\n        self.conv = nn.Conv2d(\n            in_channels=n_channels_in,\n            out_channels=n_channels_out,\n            kernel_size=kernel_size,\n            stride=1,  # striding is a cheap way to downsample, but it is less informative that Pooling after full conv.\n            dilation=1,  # dilation is a cheap way to increase receptive field, but it is less informative than deeper networks or downsampling..\n            padding=padding,\n            bias=False,  # with batchnorm, bias is ignored so optimize # params.\n        )\n        # extra sidenote stride + dilation -> equivalent to downsampling befor conv..\n        self.pool = nn.MaxPool2d(2)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.norm = nn.BatchNorm2d(n_channels_out)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pool(x)\n        x = self.relu(\n            x\n        )  # activation and pool are commutative (if activation is monotonic), so pool first to reduce calculations\n        x = self.norm(\n            x\n        )  # normalization can be used before or after activation: https://forums.fast.ai/t/order-of-layers-in-model/1261/3\n\n        return x\n\n\nclass UpSamplingBlock(nn.Module):\n    def __init__(self, n_channels_in, n_channels_out, kernel_size):\n        super().__init__()\n        self.conv = nn.Conv2d(\n            in_channels=n_channels_in * 2,\n            out_channels=n_channels_out,\n            kernel_size=kernel_size,\n            bias=False,\n            padding=\"same\",\n        )\n        self.norm = nn.BatchNorm2d(n_channels_out)\n        self.relu = nn.ReLU()\n\n    def forward(self, x, x_skip):\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = torch.cat([x, x_skip], dim=1)\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.norm(x)\n\n        return x\n\n\nclass Unet(Backbone):\n    def __init__(\n        self, n_channels_in=3, n_downsampling_layers=2, n_resnet_blocks=3, n_channels=32, kernel_size=3, **kwargs\n    ):\n        super().__init__()\n        self.n_channels = n_channels\n        self.conv1 = nn.Conv2d(n_channels_in, n_channels, kernel_size, padding=\"same\")\n\n        # create ModuleLists to ensure layers are discoverable by torch (lightning) for e.g. model summary and bringing to cuda.\n        # https://pytorch.org/docs/master/generated/torch.nn.ModuleList.html#torch.nn.ModuleList\n        self.downsampling_blocks = nn.ModuleList(\n            [MaxPoolDownSamplingBlock(n_channels, n_channels, kernel_size) for _ in range(n_downsampling_layers)]\n        )\n        self.resnet_blocks = nn.ModuleList([ResNetBlock(n_channels, n_channels) for _ in range(n_resnet_blocks)])\n        self.upsampling_blocks = nn.ModuleList(\n            [\n                UpSamplingBlock(n_channels_in=n_channels, n_channels_out=n_channels, kernel_size=kernel_size)\n                for _ in range(n_downsampling_layers)\n            ]\n        )\n\n    def forward(self, x):\n        skips = []\n\n        x = self.conv1(x)\n\n        for block in self.downsampling_blocks:\n            skips.append(x)\n            x = block(x)\n\n        for block in self.resnet_blocks:\n            x = block(x)\n\n        for block in self.upsampling_blocks:\n            x_skip = skips.pop()\n            x = block(x, x_skip)\n        return x\n\n    def get_n_channels_out(self):\n        return self.n_channels\n\n    @staticmethod\n    def add_to_argparse(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n        parser = parent_parser.add_argument_group(\"UnetBackbone\")\n        parser.add_argument(\"--n_channels_in\", type=int, default=3)\n        parser.add_argument(\"--n_channels\", type=int, default=32)\n        parser.add_argument(\"--n_resnet_blocks\", type=int, default=3)\n        parser.add_argument(\"--n_downsampling_layers\", type=int, default=2)\n        parser.add_argument(\"--kernel_size\", type=int, default=3)\n\n        return parent_parser\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:59.231992Z","iopub.execute_input":"2024-11-12T19:38:59.232349Z","iopub.status.idle":"2024-11-12T19:38:59.253796Z","shell.execute_reply.started":"2024-11-12T19:38:59.232306Z","shell.execute_reply":"2024-11-12T19:38:59.252854Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"***maxvit_unet***","metadata":{}},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nfrom torchvision.models.feature_extraction import create_feature_extractor\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\nfrom keypoint_detection.models.backbones.convnext_unet import UpSamplingBlock\n\n\nclass MaxVitUnet(Backbone):\n    \"\"\"\n    Pretrained MaxVit(MBConv (Efficient Net) + Blocked Local Attention + Grid global attention) as Encoder for the U-Net.\n\n    the outputs of the stem and all Multi-Axis (Max) stages are used as feature layers\n    note that the paper uses only stage 2-4 for segmentation w/ Mask-RCNN.\n\n    maxvit_nano_rw_256 is a version trained on 256x256 images in timm, that differs slightly from the paper\n    but is a much more lightweight model (approx. 15M params)\n\n    It is approx 4 times slower than the ConvNeXt femto backbone (5M params), and still\n    about 2 times slower than convnext_nano @ 15M params, yet provided better results\n    than both convnext variants in some initial experiments.\n\n    The model can deal with input sizes divisible by 32, but for pretrained weights you are restricted to multiples of the pretrained\n    models: 224, 256, 384. From the accompanying notebook, it seems that the model easily handles images that are 3 times as big as the\n    training size. (see https://github.com/rwightman/pytorch-image-models/issues/1475 for more details)\n\n    For now only 256 is supported so input sizes are restricted to 256,512,...\n\n\n\n    orig                    ---   1/1  -->                       --->       (head)\n        stem                ---   1/2  -->             decode4\n            stage 1         ---   1/4  -->         decode3\n                stage 2     ---   1/8  -->     decode2\n                    stage 3 ---   1/16 --> decode1\n                        stage 4 ---1/32----|\n    \"\"\"\n\n    # 15M params\n    FEATURE_CONFIG = [\n        {\"down\": 2, \"channels\": 64},\n        {\"down\": 4, \"channels\": 64},\n        {\"down\": 8, \"channels\": 128},\n        {\"down\": 16, \"channels\": 256},\n        {\"down\": 32, \"channels\": 512},\n    ]\n    MODEL_NAME = \"maxvit_nano_rw_256\"\n    feature_layers = [\"stem\", \"stages.0\", \"stages.1\", \"stages.2\", \"stages.3\"]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__()\n        self.encoder = timm.create_model(self.MODEL_NAME, pretrained=True, num_classes=0)\n        self.feature_extractor = create_feature_extractor(self.encoder, self.feature_layers)\n        self.decoder_blocks = nn.ModuleList()\n        for config_skip, config_in in zip(self.FEATURE_CONFIG, self.FEATURE_CONFIG[1:]):\n            block = UpSamplingBlock(config_in[\"channels\"], config_skip[\"channels\"], config_skip[\"channels\"], 3)\n            self.decoder_blocks.append(block)\n\n        self.final_conv = nn.Conv2d(\n            self.FEATURE_CONFIG[0][\"channels\"], self.FEATURE_CONFIG[0][\"channels\"], 3, padding=\"same\"\n        )\n        self.final_upsampling_block = UpSamplingBlock(\n            self.FEATURE_CONFIG[0][\"channels\"], 3, self.FEATURE_CONFIG[0][\"channels\"], 3\n        )\n\n    def forward(self, x):\n        orig_x = torch.clone(x)\n        features = list(self.feature_extractor(x).values())\n        x = features.pop(-1)\n        for block in self.decoder_blocks[::-1]:\n            x = block(x, features.pop(-1))\n\n        # x = nn.functional.interpolate(x, scale_factor=2)\n        # x = self.final_conv(x)\n        x = self.final_upsampling_block(x, orig_x)\n        return x\n\n    def get_n_channels_out(self):\n        return self.FEATURE_CONFIG[0][\"channels\"]\n\n\nclass MaxVitPicoUnet(MaxVitUnet):\n    MODEL_NAME = \"maxvit_rmlp_pico_rw_256\"  # 7.5M params.\n    FEATURE_CONFIG = [\n        {\"down\": 2, \"channels\": 32},\n        {\"down\": 4, \"channels\": 32},\n        {\"down\": 8, \"channels\": 64},\n        {\"down\": 16, \"channels\": 128},\n        {\"down\": 32, \"channels\": 256},\n    ]\n\n\nif __name__ == \"__main__\":\n    model = timm.create_model(\"maxvit_rmlp_pico_rw_256\")\n    # model = timm.create_model(\"maxvit_nano_rw_256\")\n    feature_extractor = create_feature_extractor(model, [\"stem\", \"stages.0\", \"stages.1\", \"stages.2\", \"stages.3\"])\n    x = torch.zeros((1, 3, 256, 256))\n    features = list(feature_extractor(x).values())\n    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"num params = {n_params/10**6:.2f} M\")\n    feature_config = []\n    for x in features:\n        print(f\"{x.shape=}\")\n        config = {\"down\": 256 // x.shape[2], \"channels\": x.shape[1]}\n        feature_config.append(config)\n    print(f\"{feature_config=}\")\n\n    model = MaxVitPicoUnet()\n    x = torch.zeros((1, 3, 256, 256))\n    y = model(x)\n    print(f\"{y.shape=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:38:59.255058Z","iopub.execute_input":"2024-11-12T19:38:59.255369Z","iopub.status.idle":"2024-11-12T19:39:17.188856Z","shell.execute_reply.started":"2024-11-12T19:38:59.255339Z","shell.execute_reply":"2024-11-12T19:39:17.187830Z"}},"outputs":[{"name":"stdout","text":"num params = 7.52 M\nx.shape=torch.Size([1, 32, 128, 128])\nx.shape=torch.Size([1, 32, 64, 64])\nx.shape=torch.Size([1, 64, 32, 32])\nx.shape=torch.Size([1, 128, 16, 16])\nx.shape=torch.Size([1, 256, 8, 8])\nfeature_config=[{'down': 2, 'channels': 32}, {'down': 4, 'channels': 32}, {'down': 8, 'channels': 64}, {'down': 16, 'channels': 128}, {'down': 32, 'channels': 256}]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/30.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80133bd614ed4b84a0f268b0f6e6dab2"}},"metadata":{}},{"name":"stdout","text":"y.shape=torch.Size([1, 32, 256, 256])\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"***mobilenetv3***","metadata":{}},{"cell_type":"code","source":"\"\"\"A MobileNetV3-based backbone.\n\"\"\"\nimport timm\nimport torch\nimport torch.nn as nn\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\nfrom keypoint_detection.models.backbones.convnext_unet import UpSamplingBlock\n\n\nclass MobileNetV3(Backbone):\n    \"\"\"\n    Pretrained MobileNetV3 using the large_100 model with 3.4M parameters.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.encoder = timm.create_model(\"mobilenetv3_large_100\", pretrained=True, features_only=True)\n        self.decoder_blocks = nn.ModuleList()\n        for i in range(1, len(self.encoder.feature_info.info)):\n            channels_in, skip_channels_in = (\n                self.encoder.feature_info.info[-i][\"num_chs\"],\n                self.encoder.feature_info.info[-i - 1][\"num_chs\"],\n            )\n            block = UpSamplingBlock(channels_in, skip_channels_in, skip_channels_in, 3)\n            self.decoder_blocks.append(block)\n\n        self.final_conv = nn.Conv2d(skip_channels_in, skip_channels_in, 3, padding=\"same\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        features = self.encoder(x)\n\n        x = features.pop()\n        for block in self.decoder_blocks:\n            x = block(x, features.pop())\n        x = nn.functional.interpolate(x, scale_factor=2)\n        x = self.final_conv(x)\n\n        return x\n\n    def get_n_channels_out(self):\n        return self.encoder.feature_info.info[0][\"num_chs\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:17.190529Z","iopub.execute_input":"2024-11-12T19:39:17.190909Z","iopub.status.idle":"2024-11-12T19:39:17.202178Z","shell.execute_reply.started":"2024-11-12T19:39:17.190871Z","shell.execute_reply":"2024-11-12T19:39:17.201406Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"***backbone_factory***","metadata":{}},{"cell_type":"code","source":"import argparse\nfrom typing import List\n\nfrom keypoint_detection.models.backbones.base_backbone import Backbone\nfrom keypoint_detection.models.backbones.convnext_unet import ConvNeXtUnet\nfrom keypoint_detection.models.backbones.dilated_cnn import DilatedCnn\nfrom keypoint_detection.models.backbones.maxvit_unet import MaxVitPicoUnet, MaxVitUnet\nfrom keypoint_detection.models.backbones.mobilenetv3 import MobileNetV3\nfrom keypoint_detection.models.backbones.s3k import S3K\nfrom keypoint_detection.models.backbones.unet import Unet\n\n\nclass BackboneFactory:\n    # TODO: how to auto-register with __init__subclass over multiple files?\n    registered_backbone_classes: List[Backbone] = [\n        Unet,\n        ConvNeXtUnet,\n        MaxVitUnet,\n        MaxVitPicoUnet,\n        S3K,\n        DilatedCnn,\n        MobileNetV3,\n    ]\n\n    @staticmethod\n    def create_backbone(backbone_type: str, **kwargs) -> Backbone:\n        for backbone_class in BackboneFactory.registered_backbone_classes:\n            if backbone_type == backbone_class.__name__:\n                return backbone_class(**kwargs)\n        raise Exception(\"Unknown backbone type\")\n\n    @staticmethod\n    def add_to_argparse(parent_parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n        parser = parent_parser.add_argument_group(BackboneFactory.__name__)\n        parser.add_argument(\n            \"--backbone_type\", type=str, default=Unet.__name__, help=\"The Class of the Backbone for the Detector.\"\n        )\n        # add all backbone hyperparams.\n        for backbone_class in BackboneFactory.registered_backbone_classes:\n            parent_parser = backbone_class.add_to_argparse(parent_parser)\n        return parent_parser\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:17.203305Z","iopub.execute_input":"2024-11-12T19:39:17.203633Z","iopub.status.idle":"2024-11-12T19:39:17.221095Z","shell.execute_reply.started":"2024-11-12T19:39:17.203584Z","shell.execute_reply":"2024-11-12T19:39:17.220324Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"***path***\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\n\ndef get_artifact_dir_path() -> Path:\n    path = Path(\"/kaggle/working/logging/artifacts\").resolve().parents[2] / \"logging\" / \"artifacts\"\n    if not os.path.exists(path):\n        path.mkdir(parents=True)\n    return str(path)\n\n\ndef get_wandb_log_dir_path() -> Path:\n    path = Path(\"/kaggle/working/logging/artifacts\").resolve().parents[2] / \"logging\" / \"wandb\"\n    if not os.path.exists(path):\n        path.mkdir(parents=True)\n    return str(path)\n\n\nif __name__ == \"__main__\":\n    print(get_artifact_dir_path())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:17.222215Z","iopub.execute_input":"2024-11-12T19:39:17.222511Z","iopub.status.idle":"2024-11-12T19:39:17.231213Z","shell.execute_reply.started":"2024-11-12T19:39:17.222478Z","shell.execute_reply":"2024-11-12T19:39:17.230334Z"}},"outputs":[{"name":"stdout","text":"/kaggle/logging/artifacts\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"***Heatmap***","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom typing import List, Optional, Tuple\n\nimport numpy as np\nimport torch\nfrom skimage.feature import peak_local_max\n\n\ndef BCE_loss(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n    \"\"\"Simple BCE loss. Used to compute the BCE of the ground truth heatmaps as the BCELoss in Pytorch complains\n    about instability in FP16 (even with no_grad).\n    \"\"\"\n    return -(\n        target * torch.clip(torch.log(input + 1e-10), -100, 100)\n        + (1 - target) * torch.clip(torch.log(1 - input + 1e-10), -100, 100)\n    ).mean()\n\n\ndef create_heatmap_batch(\n    shape: Tuple[int, int], keypoints: List[torch.Tensor], sigma: float, device: torch.device\n) -> torch.Tensor:\n    \"\"\"[summary]\n\n    Args:\n        shape (Tuple): H,W\n        keypoints (List[torch.Tensor]): N Tensors of size K_i x 2  with batch of keypoints.\n\n    Returns:\n        (torch.Tensor): N x H x W Tensor with N heatmaps\n    \"\"\"\n\n    batch_heatmaps = [generate_channel_heatmap(shape, keypoints[i], sigma, device) for i in range(len(keypoints))]\n    batch_heatmaps = torch.stack(batch_heatmaps, dim=0)\n    return batch_heatmaps\n\n\ndef generate_channel_heatmap(\n    image_size: Tuple[int, int], keypoints: torch.Tensor, sigma: float, device: torch.device\n) -> torch.Tensor:\n    \"\"\"\n    Generates heatmap with gaussian blobs for each keypoint, using the given sigma.\n    Max operation is used to combine the heatpoints to avoid local optimum surpression.\n    Origin is topleft corner and u goes right, v down.\n\n    Args:\n        image_size: Tuple(int,int) that specify (H,W) of the heatmap image\n        keypoints: a 2D Tensor K x 2,  with K keypoints  (u,v).\n        sigma: (float) std deviation of the blobs\n        device: the device on which to allocate new tensors\n\n    Returns:\n         Torch.tensor:  A Tensor with the combined heatmaps of all keypoints.\n    \"\"\"\n\n    assert isinstance(keypoints, torch.Tensor)\n\n    if keypoints.numel() == 0:\n        # special case for which there are no keypoints in this channel.\n        return torch.zeros(image_size, device=device)\n\n    u_axis = torch.linspace(0, image_size[1] - 1, image_size[1], device=device)\n    v_axis = torch.linspace(0, image_size[0] - 1, image_size[0], device=device)\n    # create grid values in 2D with x and y coordinate centered aroud the keypoint\n    v_grid, u_grid = torch.meshgrid(v_axis, u_axis, indexing=\"ij\")  # v-axis -> dim 0, u-axis -> dim 1\n\n    u_grid = u_grid.unsqueeze(0) - keypoints[..., 0].unsqueeze(-1).unsqueeze(-1)\n    v_grid = v_grid.unsqueeze(0) - keypoints[..., 1].unsqueeze(-1).unsqueeze(-1)\n\n    ## create gaussian around the centered 2D grids $ exp ( -0.5 (x**2 + y**2) / sigma**2)$\n    heatmap = torch.exp(\n        -0.5 * (torch.square(u_grid) + torch.square(v_grid)) / torch.square(torch.tensor([sigma], device=device))\n    )\n    heatmap = torch.max(heatmap, dim=0)[0]\n    return heatmap\n\n\ndef get_keypoints_from_heatmap_scipy(\n    heatmap: torch.Tensor, min_keypoint_pixel_distance: int, max_keypoints: int = 20\n) -> List[Tuple[int, int]]:\n    \"\"\"\n    Extracts at most 20 keypoints from a heatmap, where each keypoint is defined as being a local maximum within a 2D mask [ -min_pixel_distance, + pixel_distance]^2\n    cf https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.peak_local_max\n\n    THIS IS SLOW! use get_keypoints_from_heatmap_batch_maxpool instead.\n\n\n    Args:\n        heatmap : heatmap image\n        min_keypoint_pixel_distance : The size of the local mask, serves as NMS\n        max_keypoints: the amount of keypoints to determine from the heatmap, -1 to return all points. Defaults to 20 to limit computational burder\n        for models that predict random keypoints in early stage of training.\n\n    Returns:\n        A list of 2D keypoints\n    \"\"\"\n    warnings.warn(\"get_keypoints_from_heatmap_scipy is slow! Use get_keypoints_from_heatmap_batch_maxpool instead.\")\n    np_heatmap = heatmap.cpu().numpy().astype(np.float32)\n\n    # num_peaks and rel_threshold are set to limit computational burden when models do random predictions.\n    max_keypoints = max_keypoints if max_keypoints > 0 else np.inf\n    keypoints = peak_local_max(\n        np_heatmap,\n        min_distance=min_keypoint_pixel_distance,\n        threshold_rel=0.1,\n        threshold_abs=0.1,\n        num_peaks=max_keypoints,\n    )\n\n    return keypoints[::, ::-1].tolist()  # convert to (u,v) aka (col,row) coord frame from (row,col)\n\n\ndef get_keypoints_from_heatmap_batch_maxpool(\n    heatmap: torch.Tensor,\n    max_keypoints: int = 20,\n    min_keypoint_pixel_distance: int = 1,\n    abs_max_threshold: Optional[float] = None,\n    rel_max_threshold: Optional[float] = None,\n    return_scores: bool = False,\n) -> List[List[List[Tuple[int, int]]]]:\n    \"\"\"Fast extraction of keypoints from a batch of heatmaps using maxpooling.\n\n    Inspired by mmdetection and CenterNet:\n      https://mmdetection.readthedocs.io/en/v2.13.0/_modules/mmdet/models/utils/gaussian_target.html\n\n    Args:\n        heatmap (torch.Tensor): NxCxHxW heatmap batch\n        max_keypoints (int, optional): max number of keypoints to extract, lowering will result in faster execution times. Defaults to 20.\n        min_keypoint_pixel_distance (int, optional): _description_. Defaults to 1.\n\n        Following thresholds can be used at inference time to select where you want to be on the AP curve. They should ofc. not be used for training\n        abs_max_threshold (Optional[float], optional): _description_. Defaults to None.\n        rel_max_threshold (Optional[float], optional): _description_. Defaults to None.\n\n    Returns:\n        The extracted keypoints for each batch, channel and heatmap; and their scores\n    \"\"\"\n\n    # TODO: maybe separate the thresholding into another function to make sure it is not used during training, where it should not be used?\n\n    # TODO: ugly that the output can change based on a flag.. should always return scores and discard them when I don't need them...\n\n    batch_size, n_channels, _, width = heatmap.shape\n\n    # obtain max_keypoints local maxima for each channel (w/ maxpool)\n\n    kernel = min_keypoint_pixel_distance * 2 + 1\n    pad = min_keypoint_pixel_distance\n    # exclude border keypoints by padding with highest possible value\n    # bc the borders are more susceptible to noise and could result in false positives\n    padded_heatmap = torch.nn.functional.pad(heatmap, (pad, pad, pad, pad), mode=\"constant\", value=1.0)\n    max_pooled_heatmap = torch.nn.functional.max_pool2d(padded_heatmap, kernel, stride=1, padding=0)\n    # if the value equals the original value, it is the local maximum\n    local_maxima = max_pooled_heatmap == heatmap\n    # all values to zero that are not local maxima\n    heatmap = heatmap * local_maxima\n\n    # extract top-k from heatmap (may include non-local maxima if there are less peaks than max_keypoints)\n    scores, indices = torch.topk(heatmap.view(batch_size, n_channels, -1), max_keypoints, sorted=True)\n    indices = torch.stack([torch.div(indices, width, rounding_mode=\"floor\"), indices % width], dim=-1)\n    # at this point either score > 0.0, in which case the index is a local maximum\n    # or score is 0.0, in which case topk returned non-maxima, which will be filtered out later.\n\n    #  remove top-k that are not local maxima and threshold (if required)\n    # thresholding shouldn't be done during training\n\n    #  moving them to CPU now to avoid multiple GPU-mem accesses!\n    indices = indices.detach().cpu().numpy()\n    scores = scores.detach().cpu().numpy()\n    filtered_indices = [[[] for _ in range(n_channels)] for _ in range(batch_size)]\n    filtered_scores = [[[] for _ in range(n_channels)] for _ in range(batch_size)]\n    # determine NMS threshold\n    threshold = 0.01  # make sure it is > 0 to filter out top-k that are not local maxima\n    if abs_max_threshold is not None:\n        threshold = max(threshold, abs_max_threshold)\n    if rel_max_threshold is not None:\n        threshold = max(threshold, rel_max_threshold * heatmap.max())\n\n    # have to do this manually as the number of maxima for each channel can be different\n    for batch_idx in range(batch_size):\n        for channel_idx in range(n_channels):\n            candidates = indices[batch_idx, channel_idx]\n            for candidate_idx in range(candidates.shape[0]):\n\n                # these are filtered out directly.\n                if scores[batch_idx, channel_idx, candidate_idx] > threshold:\n                    # convert to (u,v)\n                    filtered_indices[batch_idx][channel_idx].append(candidates[candidate_idx][::-1].tolist())\n                    filtered_scores[batch_idx][channel_idx].append(scores[batch_idx, channel_idx, candidate_idx])\n    if return_scores:\n        return filtered_indices, filtered_scores\n    else:\n        return filtered_indices\n\n\ndef compute_keypoint_probability(heatmap: torch.Tensor, detected_keypoints: List[Tuple[int, int]]) -> List[float]:\n    \"\"\"Compute probability measure for each detected keypoint on the heatmap\n\n    Args:\n        heatmap: Heatmap\n        detected_keypoints: List of extreacted keypoints\n\n    Returns:\n        : [description]\n    \"\"\"\n    # note the order! (u,v) is how we write , but the heatmap has to be indexed (v,u) as it is H x W\n    return [heatmap[k[1]][k[0]].item() for k in detected_keypoints]\n\n\nif __name__ == \"__main__\":\n    import torch.profiler as profiler\n\n    keypoints = torch.tensor([[150, 134], [64, 153]]).cuda()\n    heatmap = generate_channel_heatmap((1080, 1920), keypoints, 6, \"cuda\")\n    heatmap = heatmap.unsqueeze(0).unsqueeze(0).repeat(1, 1, 1, 1)\n    # heatmap = torch.stack([heatmap, heatmap], dim=0)\n    print(heatmap.shape)\n    with profiler.profile(record_shapes=True) as prof:\n        with profiler.record_function(\"get_keypoints_from_heatmap_batch_maxpool\"):\n            print(get_keypoints_from_heatmap_batch_maxpool(heatmap, 50, min_keypoint_pixel_distance=5))\n    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:17.232569Z","iopub.execute_input":"2024-11-12T19:39:17.232889Z","iopub.status.idle":"2024-11-12T19:39:17.902151Z","shell.execute_reply.started":"2024-11-12T19:39:17.232855Z","shell.execute_reply":"2024-11-12T19:39:17.901293Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 1, 1080, 1920])\n[[[[150, 134], [64, 153]]]]\n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n               get_keypoints_from_heatmap_batch_maxpool         3.90%       7.664ms        99.99%     196.511ms     196.511ms       0.000us         0.00%       3.663ms       3.663ms             1  \n                                       cudaLaunchKernel        79.76%     156.750ms        79.76%     156.750ms       6.531ms       0.000us         0.00%       0.000us       0.000us            24  \n                                             aten::topk         4.26%       8.363ms        31.84%      62.581ms      62.581ms       1.225ms         0.69%       1.225ms       1.225ms             1  \n                                              aten::pad         0.42%     820.487us        18.80%      36.936ms      36.936ms       0.000us         0.00%     117.727us     117.727us             1  \n                                  aten::constant_pad_nd         2.19%       4.306ms        18.38%      36.116ms      36.116ms       0.000us         0.00%     117.727us     117.727us             1  \n                                        aten::remainder         1.33%       2.607ms        14.41%      28.322ms      28.322ms       3.584us         0.00%       3.584us       3.584us             1  \n                                               aten::eq         1.34%       2.624ms        12.50%      24.559ms      24.559ms      78.495us         0.04%      78.495us      78.495us             1  \n                                              aten::div         0.51%     994.138us         9.60%      18.862ms      18.862ms       3.968us         0.00%       3.968us       3.968us             1  \n                                            aten::copy_         0.55%       1.074ms         8.14%      16.000ms       5.333ms      87.583us         0.05%      87.583us      29.194us             3  \n                                            aten::stack         0.01%      22.446us         6.42%      12.613ms      12.613ms       0.000us         0.00%       4.448us       4.448us             1  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 196.521ms\nSelf CUDA time total: 178.498ms\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"***Visualiztion***","metadata":{}},{"cell_type":"code","source":"import argparse\nimport sys\n\n# Default paths for Kaggle or Jupyter notebook environment\njson_dataset_path = \"/kaggle/working/keypoint-detection/keypoint_detection/data/coco_dataset.py\"\nkeypoint_channel_configuration = \"/kaggle/working/keypoint-detection/keypoint_detection/models\"\n\n# Check if running in a notebook environment\nif 'ipykernel' not in sys.modules:\n    # Only use argparse if not in a notebook\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"json_dataset_path\", help=\"Path to the JSON dataset\")\n    parser.add_argument(\"keypoint_channel_configuration\", help=\"Path to keypoint channel configuration\")\n    args = parser.parse_args()\n    json_dataset_path = args.json_dataset_path\n    keypoint_channel_configuration = args.keypoint_channel_configuration\n\n# Print the paths to verify they are set\nprint(\"Dataset Path:\", json_dataset_path)\nprint(\"Model Configuration Path:\", keypoint_channel_configuration)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:17.903332Z","iopub.execute_input":"2024-11-12T19:39:17.903668Z","iopub.status.idle":"2024-11-12T19:39:17.910657Z","shell.execute_reply.started":"2024-11-12T19:39:17.903607Z","shell.execute_reply":"2024-11-12T19:39:17.909808Z"}},"outputs":[{"name":"stdout","text":"Dataset Path: /kaggle/working/keypoint-detection/keypoint_detection/data/coco_dataset.py\nModel Configuration Path: /kaggle/working/keypoint-detection/keypoint_detection/models\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from argparse import ArgumentParser\nfrom typing import List, Tuple\n\nimport numpy as np\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageFont\n\nfrom keypoint_detection.utils.heatmap import generate_channel_heatmap\n\n# Kelly's 22 colors for max contrast\nDISTINCT_COLORS = [\n    \"#F2F3F4\", \"#222222\", \"#F3C300\", \"#875692\", \"#F38400\", \"#A1CAF1\",\n    \"#BE0032\", \"#C2B280\", \"#848482\", \"#008856\", \"#E68FAC\", \"#0067A5\",\n    \"#F99379\", \"#604E97\", \"#F6A600\", \"#B3446C\", \"#DCD300\", \"#882D17\",\n    \"#8DB600\", \"#654522\", \"#E25822\", \"#2B3D26\",\n]\n\ndef get_logging_label_from_channel_configuration(channel_configuration: List[List[str]], mode: str) -> str:\n    channel_name = channel_configuration\n    if isinstance(channel_configuration, list):\n        if len(channel_configuration) == 1:\n            channel_name = channel_configuration[0]\n        else:\n            channel_name = f\"{channel_configuration[0]}+{channel_configuration[1]}+...\"\n    channel_name_short = (channel_name[:40] + \"...\") if len(channel_name) > 40 else channel_name\n    if mode != \"\":\n        label = f\"{channel_name_short}_{mode}\"\n    else:\n        label = channel_name_short\n    return label\n\ndef overlay_image_with_heatmap(images: torch.Tensor, heatmaps: torch.Tensor, alpha=0.5) -> torch.Tensor:\n    \"\"\"Overlay the images with heatmap.\"\"\"\n    viridis = plt.colormaps[\"viridis\"]  # Corrected colormap access\n    heatmaps = viridis(heatmaps.numpy())[..., :3]  # viridis: grayscale -> RGBa\n    heatmaps = torch.tensor(heatmaps, dtype=torch.float32)\n    heatmaps = heatmaps.permute((0, 3, 1, 2))  # HxWxC -> CxHxW for pytorch\n\n    overlayed_images = alpha * images + (1 - alpha) * heatmaps\n    return overlayed_images\n\ndef visualize_predicted_heatmaps(\n    imgs: torch.Tensor,\n    predicted_heatmaps: torch.Tensor,\n    gt_heatmaps: torch.Tensor,\n):\n    num_images = min(predicted_heatmaps.shape[0], 6)\n\n    predicted_heatmap_overlays = overlay_image_with_heatmap(imgs[:num_images], predicted_heatmaps[:num_images])\n    gt_heatmap_overlays = overlay_image_with_heatmap(imgs[:num_images], gt_heatmaps[:num_images])\n\n    images = torch.cat([predicted_heatmap_overlays, gt_heatmap_overlays])\n    grid = torchvision.utils.make_grid(images, nrow=num_images)\n    return grid\n\ndef overlay_images_with_keypoints(images: torch.Tensor, keypoints: List[torch.Tensor], sigma: float) -> torch.Tensor:\n    image_size = images.shape[2:]\n    alpha = 0.7\n    keypoint_color = torch.Tensor([240.0, 240.0, 10.0]) / 255.0\n    keypoint_color = keypoint_color.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n    overlayed_images = []\n    for i in range(images.shape[0]):\n\n        heatmaps = generate_channel_heatmap(image_size, keypoints[i], sigma=sigma, device=\"cpu\")\n        heatmaps = heatmaps.unsqueeze(0)  # 1 xC x H x W\n        colorized_heatmaps = keypoint_color * heatmaps\n        combined_heatmap = torch.max(colorized_heatmaps, dim=1)[0]  # 3 x H x W\n        combined_heatmap[combined_heatmap < 0.1] = 0.0  # avoid glare\n\n        overlayed_image = images[i] * alpha + combined_heatmap\n        overlayed_image = torch.clip(overlayed_image, 0.0, 1.0)\n        overlayed_images.append(overlayed_image)\n    overlayed_images = torch.stack(overlayed_images)\n    return overlayed_images\n\ndef draw_keypoints_on_image(\n    image: Image, image_keypoints: List[List[Tuple[int, int]]], channel_configuration: List[List[str]]\n) -> Image:\n    color_pool = DISTINCT_COLORS\n    image_size = image.size\n    min_size = min(image_size)\n    scale = 1 + (min_size // 256)\n\n    draw = ImageDraw.Draw(image)\n    for channel_idx, channel_keypoints in enumerate(image_keypoints):\n        for keypoint_idx, keypoint in enumerate(channel_keypoints):\n            u, v = keypoint\n            draw.ellipse((u - scale, v - scale, u + scale, v + scale), fill=color_pool[channel_idx])\n\n        draw.text(\n            (10, channel_idx * 10 * scale),\n            get_logging_label_from_channel_configuration(channel_configuration[channel_idx], \"\"),\n            fill=color_pool[channel_idx],\n            font=ImageFont.truetype(\"FreeMono.ttf\", size=10 * scale),\n        )\n\n    return image\n\ndef visualize_predicted_keypoints(\n    images: torch.Tensor, keypoints: List[List[List[List[int]]]], channel_configuration: List[List[str]]\n):\n    drawn_images = []\n    num_images = min(images.shape[0], 6)\n    for i in range(num_images):\n        image = images[i].permute(1, 2, 0).numpy() * 255\n        image = image.astype(np.uint8)\n        image = Image.fromarray(image)\n        image = draw_keypoints_on_image(image, keypoints[i], channel_configuration)\n        drawn_images.append(image)\n\n    drawn_images = torch.stack([torch.from_numpy(np.array(image)).permute(2, 0, 1) / 255 for image in drawn_images])\n\n    grid = torchvision.utils.make_grid(drawn_images, nrow=num_images)\n    return grid\n\nif __name__ == \"__main__\":\n    import matplotlib.pyplot as plt\n    from torch.utils.data import DataLoader\n\n    from keypoint_detection.data.coco_dataset import COCOKeypointsDataset\n    from keypoint_detection.tasks.train import parse_channel_configuration\n    from keypoint_detection.utils.heatmap import create_heatmap_batch\n\n    # Set the paths here directly\n    json_dataset_path = \"/kaggle/working/keypoint-detection/test/test_dataset/coco_dataset.json\"\n    keypoint_channel_configuration = \"/path/to/your/keypoint/channel/config\"  # Replace with your actual path\n\n    # Parse the channel configuration\n    hparams = {\n        \"json_dataset_path\": json_dataset_path,\n        \"keypoint_channel_configuration\": parse_channel_configuration(keypoint_channel_configuration),\n    }\n\n    dataset = COCOKeypointsDataset(**hparams)\n    batch_size = 6\n    dataloader = DataLoader(dataset, batch_size, shuffle=False, num_workers=0, collate_fn=dataset.collate_fn)\n    images, keypoint_channels = next(iter(dataloader))\n\n    shape = images.shape[2:]\n\n    heatmaps = create_heatmap_batch(shape, keypoint_channels[0], sigma=6.0, device=\"cpu\")\n    grid = visualize_predicted_heatmaps(images, heatmaps, heatmaps)\n\n    image_numpy = grid.permute(1, 2, 0).numpy()\n    plt.imshow(image_numpy)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:17.912060Z","iopub.execute_input":"2024-11-12T19:39:17.912348Z","iopub.status.idle":"2024-11-12T19:39:18.282365Z","shell.execute_reply.started":"2024-11-12T19:39:17.912318Z","shell.execute_reply":"2024-11-12T19:39:18.281419Z"}},"outputs":[{"name":"stdout","text":"detect_only_visible_keypoints=True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"***MEtrics***","metadata":{}},{"cell_type":"code","source":"\"\"\"\nImplementation of (mean) Average Precision metric for 2D keypoint detection.\n\"\"\"\n\nfrom __future__ import annotations  # allow typing of own class objects\n\nimport copy\nimport math\nfrom dataclasses import dataclass\nfrom typing import Callable, Dict, List, Tuple\n\nimport torch\nfrom torchmetrics import Metric\nfrom torchmetrics.utilities import check_forward_full_state_property\n\n\n@dataclass\nclass Keypoint:\n    \"\"\"A simple class datastructure for Keypoints,\n    dataclass is chosen over named tuple because this class is inherited by other classes\n    \"\"\"\n\n    u: int\n    v: int\n\n    def l2_distance(self, keypoint: Keypoint):\n        return math.sqrt((self.u - keypoint.u) ** 2 + (self.v - keypoint.v) ** 2)\n\n\n@dataclass\nclass DetectedKeypoint(Keypoint):\n    probability: float\n\n\n@dataclass(unsafe_hash=True)\nclass ClassifiedKeypoint(DetectedKeypoint):\n    \"\"\"\n    DataClass for a classified keypoint, where classified means determining if the detection is a True Positive of False positive,\n     with the given treshold distance and the gt keypoints from the frame\n\n    a hash is required for torch metric\n    cf https://github.com/PyTorchLightning/metrics/blob/2c8e46f87cb67186bff2c7b94bf1ec37486873d4/torchmetrics/metric.py#L570\n    unsafe_hash -> dirty fix to allow for hash w/o explictly telling python the object is immutable.\n    \"\"\"\n\n    threshold_distance: int\n    true_positive: bool\n\n\ndef keypoint_classification(\n    detected_keypoints: List[DetectedKeypoint],\n    ground_truth_keypoints: List[Keypoint],\n    threshold_distance: int,\n) -> List[ClassifiedKeypoint]:\n    \"\"\"Classifies keypoints of a **single** frame in True Positives or False Positives by searching for unused gt keypoints in prediction probability order\n    that are within distance d of the detected keypoint (greedy matching).\n\n    Args:\n        detected_keypoints (List[DetectedKeypoint]): The detected keypoints in the frame\n        ground_truth_keypoints (List[Keypoint]): The ground truth keypoints of a frame\n        threshold_distance: maximal distance in pixel coordinate space between detected keypoint and ground truth keypoint to be considered a TP\n\n    Returns:\n        List[ClassifiedKeypoint]: Keypoints with TP label.\n    \"\"\"\n    classified_keypoints: List[ClassifiedKeypoint] = []\n\n    ground_truth_keypoints = copy.deepcopy(\n        ground_truth_keypoints\n    )  # make deep copy to do local removals (pass-by-reference..)\n\n    for detected_keypoint in sorted(detected_keypoints, key=lambda x: x.probability, reverse=True):\n        matched = False\n        for gt_keypoint in ground_truth_keypoints:\n            distance = detected_keypoint.l2_distance(gt_keypoint)\n            # add small epsilon to avoid numerical errors\n            if distance <= threshold_distance + 1e-5:\n                classified_keypoint = ClassifiedKeypoint(\n                    detected_keypoint.u,\n                    detected_keypoint.v,\n                    detected_keypoint.probability,\n                    threshold_distance,\n                    True,\n                )\n                matched = True\n                # remove keypoint from gt to avoid muliple matching\n                ground_truth_keypoints.remove(gt_keypoint)\n                break\n        if not matched:\n            classified_keypoint = ClassifiedKeypoint(\n                detected_keypoint.u,\n                detected_keypoint.v,\n                detected_keypoint.probability,\n                threshold_distance,\n                False,\n            )\n        classified_keypoints.append(classified_keypoint)\n\n    return classified_keypoints\n\n\ndef calculate_precision_recall(\n    classified_keypoints: List[ClassifiedKeypoint], total_ground_truth_keypoints: int\n) -> Tuple[List[float], List[float]]:\n    \"\"\"Calculates precision recall points on the curve for the given keypoints by varying the treshold probability to all detected keypoints\n     (i.e. by always taking one additional keypoint als a predicted event)\n\n    Note that this function is tailored towards a Detector, not a Classifier. For classifiers, the outputs contain both TP, FP and FN. Whereas for a Detector the\n    outputs only define the TP and the FP; the FN are not contained in the output as the point is exactly that the detector did not detect this event.\n\n    A detector is a ROI finder + classifier and the ROI finder could miss certain regions, which results in FNs that are hence never passed to the classifier.\n\n    This also explains why the scikit average_precision function states it is for Classification tasks only. Since it takes \"total_gt_events\" to be the # of positive_class labels.\n    The function can however be used by using as label (TP = 1, FP = 0) and by then multiplying the result with TP/(TP + FN) since the recall values are then corrected\n    to take the unseen events (FN's) into account as well. They do not matter for precision calcultations.\n    Args:\n        classified_keypoints (List[ClassifiedKeypoint]):\n        total_ground_truth_keypoints (int):\n\n    Returns:\n        Tuple[List[float], List[float]]: precision, recall entries. First entry is (1,0); last entry is (0,1).\n    \"\"\"\n    precision = [1.0]\n    recall = [0.0]\n\n    true_positives = 0\n    false_positives = 0\n\n    for keypoint in sorted(classified_keypoints, key=lambda x: x.probability, reverse=True):\n        if keypoint.true_positive:\n            true_positives += 1\n        else:\n            false_positives += 1\n\n        precision.append(_zero_aware_division(true_positives, (true_positives + false_positives)))\n        recall.append(_zero_aware_division(true_positives, total_ground_truth_keypoints))\n\n    precision.append(0.0)\n    recall.append(1.0)\n    return precision, recall\n\n\ndef calculate_ap_from_pr(precision: List[float], recall: List[float]) -> float:\n    \"\"\"Calculates the Average Precision using the AUC definition (COCO-style)\n\n    # https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173\n    # AUC AP.\n\n    Args:\n        precision (List[float]):\n        recall (List[float]):\n\n    Returns:\n        (float): average precision (between 0 and 1)\n    \"\"\"\n\n    smoothened_precision = copy.deepcopy(precision)\n\n    for i in range(len(smoothened_precision) - 2, 0, -1):\n        smoothened_precision[i] = max(smoothened_precision[i], smoothened_precision[i + 1])\n\n    ap = 0\n    for i in range(len(recall) - 1):\n        ap += (recall[i + 1] - recall[i]) * smoothened_precision[i + 1]\n\n    return ap\n\n\nclass KeypointAPMetric(Metric):\n    \"\"\"torchmetrics-like interface for the Average Precision implementation\"\"\"\n\n    full_state_update = False\n\n    def __init__(self, keypoint_threshold_distance: float, dist_sync_on_step=False):\n        \"\"\"\n\n        Args:\n            keypoint_threshold_distance (float): distance from ground_truth keypoint that is used to classify keypoint as TP or FP.\n        \"\"\"\n\n        super().__init__(dist_sync_on_step=dist_sync_on_step)\n\n        self.keypoint_threshold_distance = keypoint_threshold_distance\n\n        default: Callable = lambda: []\n        self.add_state(\"classified_keypoints\", default=default(), dist_reduce_fx=\"cat\")  # list of ClassifiedKeypoints\n        self.add_state(\"total_ground_truth_keypoints\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n\n    def update(self, detected_keypoints: List[DetectedKeypoint], gt_keypoints: List[Keypoint]):\n\n        classified_img_keypoints = keypoint_classification(\n            detected_keypoints, gt_keypoints, self.keypoint_threshold_distance\n        )\n\n        self.classified_keypoints += classified_img_keypoints\n\n        self.total_ground_truth_keypoints += len(gt_keypoints)\n\n    def compute(self):\n        p, r = calculate_precision_recall(self.classified_keypoints, int(self.total_ground_truth_keypoints.cpu()))\n        m_ap = calculate_ap_from_pr(p, r)\n        return m_ap\n\n\nclass KeypointAPMetrics(Metric):\n    \"\"\"\n    Torchmetrics-like interface for calculating average precisions over different keypoint_threshold_distances.\n    Uses KeypointAPMetric class.\n    \"\"\"\n\n    full_state_update = False\n\n    def __init__(self, keypoint_threshold_distances: List[int], dist_sync_on_step=False):\n        super().__init__(dist_sync_on_step=dist_sync_on_step)\n\n        self.ap_metrics = [KeypointAPMetric(dst, dist_sync_on_step) for dst in keypoint_threshold_distances]\n\n    def update(self, detected_keypoints: List[DetectedKeypoint], gt_keypoints: List[Keypoint]):\n        for metric in self.ap_metrics:\n            metric.update(detected_keypoints, gt_keypoints)\n\n    def compute(self) -> Dict[float, float]:\n        result_dict = {}\n        for metric in self.ap_metrics:\n            result_dict.update({metric.keypoint_threshold_distance: metric.compute()})\n        return result_dict\n\n    def reset(self) -> None:\n        for metric in self.ap_metrics:\n            metric.reset()\n\n\ndef _zero_aware_division(num: float, denom: float) -> float:\n    if num == 0:\n        return 0\n    if denom == 0 and num != 0:\n        return float(\"inf\")\n    else:\n        return num / denom\n\n\nif __name__ == \"__main__\":\n    print(\n        check_forward_full_state_property(\n            KeypointAPMetric,\n            init_args={\"keypoint_threshold_distance\": 2.0},\n            input_args={\"detected_keypoints\": [DetectedKeypoint(10, 20, 0.02)], \"gt_keypoints\": [Keypoint(10, 23)]},\n        )\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:39:18.283684Z","iopub.execute_input":"2024-11-12T19:39:18.284009Z","iopub.status.idle":"2024-11-12T19:41:01.324115Z","shell.execute_reply.started":"2024-11-12T19:39:18.283976Z","shell.execute_reply":"2024-11-12T19:41:01.323086Z"}},"outputs":[{"name":"stdout","text":"Full state for 10 steps took: 0.004137965384870768+-0.001\nPartial state for 10 steps took: 0.003+-0.001\nFull state for 100 steps took: 0.12354826927185059+-0.000\nPartial state for 100 steps took: 0.119+-0.001\nFull state for 1000 steps took: 10.206430435180664+-0.141\nPartial state for 1000 steps took: 10.140+-0.140\nRecommended setting `full_state_update=False`\nNone\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"***load detectors***","metadata":{}},{"cell_type":"code","source":"print('helooo')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:41:01.325163Z","iopub.execute_input":"2024-11-12T19:41:01.325443Z","iopub.status.idle":"2024-11-12T19:41:01.330683Z","shell.execute_reply.started":"2024-11-12T19:41:01.325414Z","shell.execute_reply":"2024-11-12T19:41:01.329661Z"}},"outputs":[{"name":"stdout","text":"helooo\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import wandb\nfrom pathlib import Path\nimport torch\nfrom keypoint_detection.models.backbones.backbone_factory import BackboneFactory\nfrom keypoint_detection.models.detector import KeypointDetector\n\n# Login to W&B manually if not already done\nwandb.login()\n\ndef get_model_from_wandb_checkpoint(checkpoint_reference: str):\n    \"\"\"\n    Get a model from a PyTorch Lightning checkpoint stored on W&B as an artifact.\n    \"\"\"\n    # Start a W&B run\n    with wandb.init(project=\"hardy-paper-6\", entity=\"tinsaiebbs\") as run:\n        # Download checkpoint locally (if not already cached)\n        artifact = run.use_artifact(checkpoint_reference, type=\"model\")\n        artifact_dir = artifact.download()\n        checkpoint_path = Path(artifact_dir) / \"model.ckpt\"\n        return load_from_checkpoint(checkpoint_path)\n\ndef load_from_checkpoint(checkpoint_path: str, hparams_to_override: dict = None):\n    \"\"\"\n    Function to load a Keypoint Detector model from a local PyTorch Lightning checkpoint.\n    \"\"\"\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    backbone = BackboneFactory.create_backbone(**checkpoint[\"hyper_parameters\"])\n    model = KeypointDetector.load_from_checkpoint(checkpoint_path, backbone=backbone, map_location=device)\n    return model\n\nif __name__ == \"__main__\":\n    checkpoint_reference = \"tinsaiebbs/hardy-paper-6/model-4um302zo:v0\"\n    model = get_model_from_wandb_checkpoint(checkpoint_reference)\n    print(model.hparams)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:41:01.331823Z","iopub.execute_input":"2024-11-12T19:41:01.332147Z","iopub.status.idle":"2024-11-12T19:41:04.461377Z","shell.execute_reply.started":"2024-11-12T19:41:01.332115Z","shell.execute_reply":"2024-11-12T19:41:04.457457Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtinsaiebbs\u001b[0m (\u001b[33mtinsaiebbss\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtinsaiebbs\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     33\u001b[0m     checkpoint_reference \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtinsaiebbs/hardy-paper-6/model-4um302zo:v0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_from_wandb_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_reference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mhparams)\n","Cell \u001b[0;32mIn[27], line 15\u001b[0m, in \u001b[0;36mget_model_from_wandb_checkpoint\u001b[0;34m(checkpoint_reference)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mGet a model from a PyTorch Lightning checkpoint stored on W&B as an artifact.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Start a W&B run\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhardy-paper-6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtinsaiebbs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Download checkpoint locally (if not already cached)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39muse_artifact(checkpoint_reference, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     artifact_dir \u001b[38;5;241m=\u001b[39m artifact\u001b[38;5;241m.\u001b[39mdownload()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1266\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[0;32m-> 1266\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/analytics/sentry.py:155\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1252\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[1;32m   1251\u001b[0m     wi\u001b[38;5;241m.\u001b[39msetup(kwargs)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:844\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m--> 844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","\u001b[0;31mCommError\u001b[0m: failed to upsert bucket: returned error 403 Forbidden: {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertBucket\":null}}"],"ename":"CommError","evalue":"failed to upsert bucket: returned error 403 Forbidden: {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertBucket\":null}}","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"wandb.init(project=\"hardy-paper-6\", entity=\"tinsaiebbs\", mode=\"offline\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:41:04.462589Z","iopub.status.idle":"2024-11-12T19:41:04.462986Z","shell.execute_reply.started":"2024-11-12T19:41:04.462802Z","shell.execute_reply":"2024-11-12T19:41:04.462821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.init(project=\"hardy-paper-6\", entity=\"tinsaiebbs\", sync_tensorboard=False, settings=wandb.Settings(start_method=\"thread\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:41:04.464200Z","iopub.status.idle":"2024-11-12T19:41:04.464580Z","shell.execute_reply.started":"2024-11-12T19:41:04.464402Z","shell.execute_reply":"2024-11-12T19:41:04.464420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}